{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_dynamic_tables(url):\n",
    "    # Set the path of the Edge driver \n",
    "    # If it's in your PATH, you can skip this line\n",
    "    driver_path = \"C:\\\\Users\\\\rodri\\\\Dropbox\\\\PC (3)\\\\Downloads\\\\edgedriver_win64 (4)\\\\msedgedriver.exe\"\n",
    "\n",
    "    # Start a browser\n",
    "    driver = webdriver.Edge(executable_path=driver_path)\n",
    "\n",
    "    # Fetch the page\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to fully load\n",
    "    time.sleep(5)  # adjust this delay as needed\n",
    "\n",
    "    # Parse the HTML content of the page with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # List to store all DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    for table in tables:\n",
    "        # Find all rows in the table\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        # Extract the text from the header cells\n",
    "        headers = [th.text for th in rows[0].find_all('th')]\n",
    "\n",
    "        # Extract the text from the remaining row cells\n",
    "        data = [[td.text for td in row.find_all('td')] for row in rows[1:]]\n",
    "\n",
    "        # Create a pandas DataFrame from the data and add it to the list\n",
    "        dfs.append(pd.DataFrame(data, columns=headers))\n",
    "\n",
    "    return dfs\n",
    "\n",
    "# Usage\n",
    "url = 'https://resultados.tsje.gov.py/publicacion/divulgacion.html'\n",
    "dataframes = scrape_dynamic_tables(url)\n",
    "\n",
    "for df in dataframes:\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
